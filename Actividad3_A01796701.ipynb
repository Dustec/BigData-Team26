{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfMQuxm2g1Iz"
   },
   "source": [
    "# **Maestría en Inteligencia Artificial Aplicada**\n",
    "## **Curso: Análisis de Grandes Volúmenes de Datos**\n",
    "### Tecnológico de Monterrey\n",
    "### Prof. Iván Olmos\n",
    "\n",
    "## **Actividad 3**\n",
    "\n",
    "### **Aprendizaje supervisado y no supervisado**\n",
    "\n",
    "##### Nombre y matrícula: Mario Guillen De La Torre - A01796701"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-l5jqG4fhkRo"
   },
   "source": [
    "\n",
    "---\n",
    "\n",
    "\n",
    "#### **Descripción de la Base de Datos:**\n",
    "\n",
    "Este notebook procesa el dataset de viajes en taxi de la ciudad de Chicago, aplicando reglas de particionamiento basadas en el tipo de pago y la zona de recojo. Posteriormente se extraen submuestras representativas que serán utilizadas para analizar el comportamiento de propinas.\n",
    "\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Marco Teórico**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **I. Introducción**\n",
    "\n",
    "Los algoritmos de machine learning se dividen principalmente en dos categorías: algoritmos supervisados y no supervisados. Cada uno espera una estructura de datos distinta y resuelven problemas de diferentes naturalezas.\n",
    "\n",
    "##### **1.1 Algoritmos Supervisados**\n",
    "Estos esperan tener una variable dependiente u “objetivo” cuya relacion con las variables independientes pueda ser analizada para encontrar relaciones y generar un modelo predictivo a usar. El tipo de dato de la variable dependiente, categórica o continua, decidirá la clase de problema a abordar, clasificación o regresión. \n",
    "\n",
    "En los problemas de clasificación se intenta predecir la categoría discreta a la que pertenece un nuevo registro, algoritmos clásicos son:\n",
    "\n",
    "- Clasificador de Naive Bayes\n",
    "- Máquinas de Soporte Vectorial (SVMs)\n",
    "- Regresión Logística\n",
    "- Árboles de decisión (y sus algoritmos derivados como bosques de decisión)\n",
    "\n",
    "La librería MLlib de PySpark tiene implementaciones de todos estos algoritmos.\n",
    "\n",
    "En los problemas de regresión, el objetivo es predecir un valor continuo en base de las variables independientes. PySpark tiene implementaciones de los siguientes algoritmos (entre otros):\n",
    "\n",
    "- Regresor de árbol de decisiones.\n",
    "- Regresor GBT (Gradient Boosted Trees)\n",
    "- Regresor FM (Factorization Machines)\n",
    "\n",
    "##### **1.2 Algoritmos No Supervisados**\n",
    "Los algoritmos no supervisados no cuentan con una variable “objetivo”, estos buscan encontrar patrones, estructuras o agrupaciones que se encuentran intrínsecamente en los datos analizados. Usos posibles de estos patrones son la toma de decisiones y reducción de dimensionalidad de los datos.\n",
    "\n",
    "Un uso común es la búsqueda de patrones frecuentes en los datos, esto es, identificar relaciones recurrentes entre las variables. PySpark implementa dos diferentes algoritmos:\n",
    "\n",
    "- FPGrowth\n",
    "- PrefixSpan\n",
    "\n",
    "Otro enfoque es el análisis de agrupamiento, en el cual se busca asociar cada registro a un grupo y calcular a qué grupo pertenece un registro nuevo, algoritmos comunes implementados por PySpark son:\n",
    "\n",
    "- LDA\n",
    "- GaussianMixture\n",
    "- KMeans\n",
    "- BisectingKMeans\n",
    "- PowerIterationClustering\n",
    "\n",
    "#### **II. Selección de los datos**\n",
    "Como se mencionó en entregas anteriores, se decidieron reglas de particionamiento basadas en tres variables de caracterización, las cuales fueron seleccionadas por su relevancia en la generación de patrones comportamentales:\n",
    "\n",
    "- payment_group: Agrupa los métodos de pago en: Credit Card, Cash, Mobile y Other. _Esta variable es fundamental, ya que existe evidencia empírica de que los pasajeros que pagan con tarjeta tienden a dejar propina con mayor frecuencia que quienes pagan en efectivo._\n",
    "\n",
    "\n",
    "- pickup_zone_group: Corresponde a la zona de inicio del viaje. Se agruparon las áreas comunitarias más representativas: 76, 8, 32, 28 y Other (cualquier otra zona).\n",
    "_Esta variable se usa como un proxy de contexto urbano y socioeconómico, dado que diferentes zonas pueden reflejar distintos perfiles de pasajeros._\n",
    "\n",
    "\n",
    "- duration_group: Se construyó a partir de la variable duration_minutes aplicando binning basado en percentiles, con los siguientes rangos: Flash Riders  ≤10 min, Urban Cruisers entre 10 y 23.2 min y Long-Haul Nomads >23.2 min.\n",
    "_Esta agrupación refleja distintos tipos de trayecto, desde viajes cortos típicos del centro urbano hasta trayectos largos, con distintas expectativas y comportamientos asociados al servicio._\n",
    "\n",
    "\n",
    "Estas tres variables definen el espacio de particionamiento, generando combinaciones que capturan diferentes perfiles de pasajeros. En total, se obtienen:\n",
    "\n",
    "- 4(payment_group) × 5(pickup_zone_group) × 3(duration_group) = **60 combinaciones de partición**\n",
    "\n",
    "Todas las combinaciones anteriores describen a un amplio rango de viajeros, por lo que inevitablemente existen aquellas combinaciones que raramente ocurren. Para reducir la complejidad de nuestro problema se combinan las particiones que ocurren menos del 2% de las veces dentro de nuestros datos, lo que reduce el número de combinaciones a 21 (contando el nuevo grupo combinado). \n",
    "\n",
    "Cada una de estas particiones representa un perfil distinto de viaje (por ejemplo, trayectos largos pagados con tarjeta y partiendo de zonas turísticas). Es importante recalcar que no todos los perfiles cuentan con la misma proporción de datos, lo que podría incurrir en sesgos si la técnica de muestreo no es definida correctamente. Es por esto que se opta por un muestreo estratificado que permite extraer una proporción balanceada de los registros, tomando en cuenta todos los grupos y evitando que el modelo aprenda patrones de solo los grupos mayoritarios.\n",
    "\n",
    "#### **REFERENCIAS**\n",
    "SmartCitiesWorld. (2022). Predictive analytics key to easing traffic congestion.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://www.smartcitiesworld.net/news/news/predictive-analytics-key-to-easing-traffic-congestion-7502\n",
    "\n",
    "Guo, Y., Liu, Y., Wang, J., & Chen, H. (2023). Urban mobility hotspots and their implications for resilient city planning.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Journal of Transport Geography, 108, 103567. https://www.sciencedirect.com/science/article/pii/S096669232300039X?via%3Dihub\n",
    "\n",
    "Le, James. (2019, Julio 23). Using Ant Colony and Genetic Evolution to Optimize Ride-Sharing Trip Duration.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Medium. https://medium.com/data-science/using-ant-colony-and-genetic-evolution-to-optimize-ride-sharing-trip-duration-56194215923f\n",
    "\n",
    "City of Chicago. (2024). Taxi Trips (2024-) [Conjunto de datos].  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;https://data.cityofchicago.org/Transportation/Taxi-Trips-2024-/ajtu-isnz/about_data\n",
    "\n",
    "Ahmed, S. K. (2024). Research methodology simplified: how to choose the right sampling technique and determine the appropriate sample size for research.  \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;Oral Oncology Reports, 12, 100662. https://doi.org/10.1016/j.oor.2024.100662\n",
    "\n",
    "Polak, A. (2023). Scaling Machine Learning with Spark: Distributed ML with MLlib, TensorFlow, and Pytorch. O’Reilly Media."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Implementación**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dcCnhJwyiTyu"
   },
   "source": [
    "#### **Importación de Librerías**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como primer paso importamos las librerías que serán necesarias para la ejecución de nuestro código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "XXKGZB4SiQjr"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import Imputer,StringIndexer,OneHotEncoder,StandardScaler,VectorAssembler\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.sql.functions import col, isnan, when, count, percentile_approx, min, max, mean, stddev, approx_count_distinct, expr,  concat_ws, lit\n",
    "from pyspark.sql.functions import hour, dayofweek, unix_timestamp, when, month,to_timestamp,  dayofweek\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, ClusteringEvaluator\n",
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "import os\n",
    "from IPython.display import display, HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LS8Q2W_nioUA"
   },
   "source": [
    "#### **Creación de la Sesión Spark**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Posteriormente, generamos nuestra sesión de Spark y definimos una función que me permitirá el imprimir los DataFrames de Spark en una vista mucho más amigable, para esto el DataFrame se convierte a un pandas DataFrame y se imprime usando HTML. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "eEuzkb88ism7"
   },
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"ChicagoTaxyTripsAnalysis\") \\\n",
    "     .config(\"spark.executor.memory\", \"4g\") \\\n",
    "    .config(\"spark.driver.memory\", \"4g\") \\\n",
    "    .config(\"spark.python.worker.timeout\", \"600\") \\\n",
    "    .config(\"spark.python.worker.retries\", \"3\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretty_display(df, limit=100):\n",
    "    pdf = df.limit(limit).toPandas()\n",
    "    display(HTML(pdf.to_html(notebook=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uzhfCehBi5hF"
   },
   "source": [
    "#### **Carga del Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora cargamos nuestro dataset y observamos el número de registros y columnas, dando una idea de la dimensión de los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q81a5PRN5X-I",
    "outputId": "b0368f99-57e9-43be-c719-56d9985e6809"
   },
   "outputs": [],
   "source": [
    "filename = \"Taxi_Trips__2024-__20250426.csv\"\n",
    "local_path = f\"C:/Users/mario/Maestria/Grandes Cantidades de Datos/{filename}\"\n",
    "dftaxytrips = spark.read.csv(local_path, header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a9j_i4-qkfh4",
    "outputId": "d8e56a64-c9ac-48f5-a459-e89b989c6355"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de registros: 7917844\n",
      "Número de columnas: 23\n"
     ]
    }
   ],
   "source": [
    "print(\"Número de registros:\", dftaxytrips.count())\n",
    "print(\"Número de columnas:\", len(dftaxytrips.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "idr7YdRflQJn"
   },
   "source": [
    "#### **Exploración de los Datos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación podemos verificar el Schema de nuestro dataset, haciendo nota de las columnas que son de tipo textual, ya que estas recibirán un trato distinto en las siguientes secciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OIvycSZ_lQxt",
    "outputId": "b1927e7f-2c38-4df6-8519-6fe9d9864820"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Trip ID: string (nullable = true)\n",
      " |-- Taxi ID: string (nullable = true)\n",
      " |-- Trip Start Timestamp: string (nullable = true)\n",
      " |-- Trip End Timestamp: string (nullable = true)\n",
      " |-- Trip Seconds: integer (nullable = true)\n",
      " |-- Trip Miles: double (nullable = true)\n",
      " |-- Pickup Census Tract: long (nullable = true)\n",
      " |-- Dropoff Census Tract: long (nullable = true)\n",
      " |-- Pickup Community Area: integer (nullable = true)\n",
      " |-- Dropoff Community Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tips: double (nullable = true)\n",
      " |-- Tolls: double (nullable = true)\n",
      " |-- Extras: double (nullable = true)\n",
      " |-- Trip Total: double (nullable = true)\n",
      " |-- Payment Type: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Pickup Centroid Latitude: double (nullable = true)\n",
      " |-- Pickup Centroid Longitude: double (nullable = true)\n",
      " |-- Pickup Centroid Location: string (nullable = true)\n",
      " |-- Dropoff Centroid Latitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Longitude: double (nullable = true)\n",
      " |-- Dropoff Centroid  Location: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dftaxytrips.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mj5F8yzJujId"
   },
   "source": [
    "#### **Variables de Caracterización**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se mencionó en entregas anteriores, para nuestro análisis se decidió realizar transformaciones a nuestros datos para generar nuevas columnas que puedan presentar con información significativa para nuestro análisis. Un ejemplo claro de esto es la creación de las columnas \"trip_hour\",\"trip_day_of_week\"y\"trip_month\" las cuales desglosan la fecha y hora del inicio de un viaje y podrían ser de gran importancia para encontrar relaciones en nuestros datos.\n",
    "\n",
    "Además, se agrupan valores en ciertas columnas y se realiza binning en otras para reducir la complejidad de nuestros datos.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "pUk-nGDRK8-b"
   },
   "outputs": [],
   "source": [
    "# Trip Start Timestamp es tipo timestamp\n",
    "dftaxytrips = dftaxytrips.withColumn(\n",
    "    \"trip_start_ts\",\n",
    "    to_timestamp(col(\"Trip Start Timestamp\"), \"MM/dd/yyyy hh:mm:ss a\")\n",
    ")\n",
    "\n",
    "# Hora del día\n",
    "dftaxytrips = dftaxytrips.withColumn(\"trip_hour\", hour(col(\"trip_start_ts\")))\n",
    "\n",
    "# Día de la semana (1 = domingo, 7 = sábado)\n",
    "dftaxytrips = dftaxytrips.withColumn(\"trip_day_of_week\", dayofweek(col(\"trip_start_ts\")))\n",
    "\n",
    "# Mes del año (1 = enero, 12 = diciembre)\n",
    "dftaxytrips = dftaxytrips.withColumn(\"trip_month\", month(col(\"trip_start_ts\")))\n",
    "\n",
    "# Duración del viaje en minutos\n",
    "dftaxytrips = dftaxytrips.withColumn(\"duration_minutes\", col(\"Trip Seconds\") / 60)\n",
    "\n",
    "# Tip/Fare ratio\n",
    "dftaxytrips = dftaxytrips.withColumn(\"tip_ratio\",\n",
    "    when(col(\"Fare\") > 0, col(\"Tips\") / col(\"Fare\")).otherwise(0))\n",
    "\n",
    "# Tip/Trip Miles ratio\n",
    "dftaxytrips = dftaxytrips.withColumn(\"tip_per_mile\",\n",
    "    when(col(\"Trip Miles\") > 0, col(\"Tips\") / col(\"Trip Miles\")).otherwise(0))\n",
    "\n",
    "# Agrupación método de pago\n",
    "dftaxytrips = dftaxytrips.withColumn(\"payment_group\",\n",
    "    when(col(\"Payment Type\") == \"Credit Card\", \"Credit Card\")\n",
    "    .when(col(\"Payment Type\") == \"Cash\", \"Cash\")\n",
    "    .when(col(\"Payment Type\") == \"Mobile\", \"Mobile\")\n",
    "    .otherwise(\"Other\"))\n",
    "\n",
    "# Agrupación de Compañia\n",
    "dftaxytrips = dftaxytrips.withColumn(\"company_group\",\n",
    "    when(col(\"Company\") == \"Flash Cab\", \"Flash Cab\")\n",
    "    .when(col(\"Company\") == \"Taxi Affiliation Services\", \"Taxi Affiliation\")\n",
    "    .when(col(\"Company\") == \"Taxicab Insurance Agency Llc\", \"Insurance Agency\")\n",
    "    .when(col(\"Company\") == \"Sun Taxi\", \"Sun Taxi\")\n",
    "    .when(col(\"Company\") == \"City Service\", \"City Service\")\n",
    "    .when(col(\"Company\") == \"Chicago Independents\", \"Chicago Independents\")\n",
    "    .otherwise(\"Other\"))\n",
    "\n",
    "# Agrupación Zona origen\n",
    "dftaxytrips = dftaxytrips.withColumn(\"pickup_zone_group\",\n",
    "    when(col(\"Pickup Community Area\") == 76, 76)\n",
    "    .when(col(\"Pickup Community Area\") == 8, 8)\n",
    "    .when(col(\"Pickup Community Area\") == 32, 32)\n",
    "    .when(col(\"Pickup Community Area\") == 28, 28)\n",
    "    .otherwise(\"Other\"))\n",
    "\n",
    "# Agrupación Zona destino\n",
    "dftaxytrips = dftaxytrips.withColumn(\"dropoff_zone_group\",\n",
    "    when(col(\"Dropoff Community Area\") == 8, 8)\n",
    "    .when(col(\"Dropoff Community Area\") == 32, 32)\n",
    "    .when(col(\"Dropoff Community Area\") == 28, 28)\n",
    "    .when(col(\"Dropoff Community Area\") == 76, 76)\n",
    "    .otherwise(\"Other\"))\n",
    "\n",
    "# Renombrar ciertas columnas\n",
    "dftaxytrips = dftaxytrips.withColumnRenamed(\"Trip ID\", \"trip_id\")\n",
    "dftaxytrips = dftaxytrips.withColumnRenamed(\"Trip Miles\", \"trip_miles\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "LoFhkJOFAGRf"
   },
   "outputs": [],
   "source": [
    "# Duración del viaje (en minutos)\n",
    "dftaxytrips = dftaxytrips.withColumn(\n",
    "    \"duration_group\",\n",
    "    (\n",
    "        when(col(\"duration_minutes\") <= 10.0, \"Flash Riders\")           # viajes muy cortos, de alta rotación\n",
    "        .when(col(\"duration_minutes\") <= 23.2, \"Urban Cruisers\")        # trayectos típicos dentro de la ciudad\n",
    "        .otherwise(\"Long-Haul Nomads\")                                  # trayectos largos, posiblemente entre distritos lejanos\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8p1No4yW29ql"
   },
   "source": [
    "#### **Regla de Particionamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kibtyqeSDksz"
   },
   "source": [
    "Debido a que el objetivo principal del proyecto está enfocado en analizar las propinas (tips) en los viajes de taxi de Chicago y predecir patrones relevantes, hemos considerado estas tres variables para realizar nuestro particionamiento:\n",
    "\n",
    "\n",
    "*   **`payment_group`:** Agrupación del método de pago Credit Card, Cash, Mobile, Other. Se considera clave debido a la fuerte relación entre pagos con tarjeta y la propina otorgada.\n",
    "*   **`pickup_zone_group`:** \tAgrupación de zonas de recojo, áreas específicas (76, 8, 32, 28) y un grupo \"Other\" que incluye las demás zonas. Representa un proxy de ubicación socioeconómica o comercial.\n",
    "*   **`duration_group`:** Clasificación de duración del viaje Flash Riders (≤10 min), Urban Cruisers (10–23.2 min), Long-Haul Nomads (>23.2 min). Captura la intensidad y contexto del trayecto.\n",
    "\n",
    "Asimismo, consideramos que estas variables permiten capturar factores clave de comportamiento relacionados con la decisión del pasajero de dejar una propina."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación realizamos el particionamiento de nuestros datos utilizando las variables mencionadas anteriormente, esto nos indicará la proporción de cada segmento ayudándonos a tomar decisiones en nuestro muestreo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u65XAmYv0X6W",
    "outputId": "a00b5ac1-9257-4180-c1bf-8a6b50cd1f46"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-----------------+----------------+------+--------------------+\n",
      "|payment_group|pickup_zone_group|  duration_group| count|          proportion|\n",
      "+-------------+-----------------+----------------+------+--------------------+\n",
      "|  Credit Card|               76|Long-Haul Nomads|932993| 0.11783422355883748|\n",
      "|        Other|            Other|  Urban Cruisers|447407| 0.05650616506210529|\n",
      "|        Other|            Other|Long-Haul Nomads|430338| 0.05435040144766681|\n",
      "|         Cash|            Other|    Flash Riders|310727| 0.03924389012968682|\n",
      "|         Cash|                8|    Flash Riders|306484| 0.03870801192849973|\n",
      "|  Credit Card|               32|    Flash Riders|291907|0.036866980455790746|\n",
      "|  Credit Card|                8|    Flash Riders|276498| 0.03492086987316244|\n",
      "|         Cash|               32|    Flash Riders|255828| 0.03231031073610442|\n",
      "|       Mobile|                8|    Flash Riders|225234|0.028446380100441485|\n",
      "|  Credit Card|            Other|Long-Haul Nomads|211508|0.026712827380786994|\n",
      "|         Cash|               76|Long-Haul Nomads|206361|0.026062776685168335|\n",
      "|         Cash|            Other|Long-Haul Nomads|205220| 0.02591867180005062|\n",
      "|       Mobile|            Other|  Urban Cruisers|203128|0.025654458461166953|\n",
      "|  Credit Card|               76|  Urban Cruisers|199533|  0.0252004207205901|\n",
      "|         Cash|            Other|  Urban Cruisers|194488| 0.02456325231969713|\n",
      "|  Credit Card|                8|  Urban Cruisers|183293|0.023149357325049597|\n",
      "|       Mobile|                8|  Urban Cruisers|179042| 0.02261246874780559|\n",
      "|  Credit Card|            Other|  Urban Cruisers|162120|0.020475270793412954|\n",
      "|         Cash|                8|  Urban Cruisers|159390|0.020130479963990196|\n",
      "|  Credit Card|               28|    Flash Riders|158992|0.020080213755158602|\n",
      "|  Credit Card|               32|  Urban Cruisers|154174|0.019471714774880636|\n",
      "|         Cash|               28|    Flash Riders|142729|0.018026245528454464|\n",
      "|  Credit Card|            Other|    Flash Riders|138692|0.017516384510732973|\n",
      "|       Mobile|               32|    Flash Riders|126880|0.016024564262695756|\n",
      "|       Mobile|               32|  Urban Cruisers|100057| 0.01263689964086183|\n",
      "|       Mobile|            Other|Long-Haul Nomads| 99085|0.012514138949946475|\n",
      "|         Cash|               32|  Urban Cruisers| 97494|0.012313200411627206|\n",
      "|       Mobile|               76|Long-Haul Nomads| 94029|0.011875581281975245|\n",
      "|  Credit Card|               28|  Urban Cruisers| 93965|0.011867498273519912|\n",
      "|  Credit Card|               32|Long-Haul Nomads| 86405|0.010912692899733817|\n",
      "|       Mobile|            Other|    Flash Riders| 85058|  0.0107425708311505|\n",
      "|  Credit Card|                8|Long-Haul Nomads| 84164|0.010629661306790082|\n",
      "|        Other|            Other|    Flash Riders| 82513|0.010421144948043937|\n",
      "|         Cash|               28|  Urban Cruisers| 80382|0.010152006025882803|\n",
      "|  Credit Card|               76|    Flash Riders| 74094|0.009357850445146431|\n",
      "|         Cash|               76|  Urban Cruisers| 71610|0.009044128679473858|\n",
      "|        Other|                8|  Urban Cruisers| 70825|0.008944985528888925|\n",
      "|         Cash|               76|    Flash Riders| 69526|0.008780925716647108|\n",
      "|       Mobile|               28|  Urban Cruisers| 67629|0.008541340294150782|\n",
      "|       Mobile|               28|    Flash Riders| 55853|0.007054066738369688|\n",
      "|        Other|                8|Long-Haul Nomads| 55355|0.006991170828826...|\n",
      "|         Cash|                8|Long-Haul Nomads| 53054|0.006700561415456025|\n",
      "|        Other|               28|  Urban Cruisers| 45480|0.005743987883570325|\n",
      "|       Mobile|                8|Long-Haul Nomads| 43276|0.005465629279889829|\n",
      "|        Other|               28|Long-Haul Nomads| 41306|0.005216824175874139|\n",
      "|        Other|               32|  Urban Cruisers| 35917|0.004536209604533759|\n",
      "|         Cash|               32|Long-Haul Nomads| 35216|0.004447675402546451|\n",
      "|        Other|               32|Long-Haul Nomads| 33669|0.004252293932540222|\n",
      "|       Mobile|               32|Long-Haul Nomads| 27848|0.003517119054126...|\n",
      "|         Cash|               28|Long-Haul Nomads| 25386|0.003206175822610...|\n",
      "|        Other|                8|    Flash Riders| 22324|0.002819454386825...|\n",
      "|  Credit Card|               28|Long-Haul Nomads| 17816|0.002250107478753...|\n",
      "|       Mobile|               76|  Urban Cruisers| 15166|0.001915420409899...|\n",
      "|       Mobile|               28|Long-Haul Nomads| 14459|0.001826128425869...|\n",
      "|        Other|               32|    Flash Riders|  9440|0.001192243747161...|\n",
      "|        Other|               76|Long-Haul Nomads|  9007|0.001137557143080869|\n",
      "|        Other|               28|    Flash Riders|  8300|0.001048265159050873|\n",
      "|        Other|               76|  Urban Cruisers|  5087| 6.42472875191782E-4|\n",
      "|        Other|               76|    Flash Riders|  2060|2.601718346559997...|\n",
      "|       Mobile|               76|    Flash Riders|  2023|2.554988453927609...|\n",
      "+-------------+-----------------+----------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "partition_counts = dftaxytrips.groupBy(\n",
    "    \"payment_group\", \"pickup_zone_group\", \"duration_group\"\n",
    ").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "# Calcular total general\n",
    "total_count = dftaxytrips.count()\n",
    "\n",
    "# Agregar proporción por combinación\n",
    "partition_counts = partition_counts.withColumn(\n",
    "    \"proportion\", col(\"count\") / total_count\n",
    ")\n",
    "\n",
    "# Ordenar por las más representativas\n",
    "partition_counts.orderBy(col(\"proportion\").desc()).show(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos ver, tenemos un total de 60 segmentos en nuestra población, muchos de estos cuentan con una cantidad muy reducida de datos, por lo que incluirlos en nuestras técnicas de muestreo puede propiciar errores y sobre complicar el proceso para segmentos muy poco representativos de la población en general. Por estas razones se opta por conglomerar aquellos que cuentan con menos de un 2% de la población en un nuevo segmento considerado \"Other\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para esto se realizan los siguientes pasos:\n",
    "- Se crea un dataset con solo los segmentos que tienen más del 2% de la población utilizando un filtro en la columna \"proportion\"\n",
    "- A dicho dataset se le agrega una columna \"StrataGrouping\" que funcionará como identificador concatenando los valores de \"payment_group\", \"pickup_zone_group\", \"duration_group\"\n",
    "- Se hace una unión al dataset original usando las tres columnas antes mencionadas, esto hace que la columna \"StrataGrouping\" tenga solo valores en aquellos segmentos con más del 2% de la población.\n",
    "- Para el resto de los segmentos se imputa el valor \"Other\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "significant_combinations = partition_counts.filter(col(\"proportion\") > 0.02)\n",
    "\n",
    "significant_combinations = significant_combinations.withColumn(\n",
    "    \"StrataGrouping\", concat_ws(\"_\", \"payment_group\", \"pickup_zone_group\", \"duration_group\")\n",
    ")\n",
    "\n",
    "dftaxytrips_with_strata = dftaxytrips.join(\n",
    "    significant_combinations.select(\n",
    "        \"payment_group\", \"pickup_zone_group\", \"duration_group\", \"StrataGrouping\"\n",
    "    ),\n",
    "    on=[\"payment_group\", \"pickup_zone_group\", \"duration_group\"],\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "dftaxytrips_with_strata = dftaxytrips_with_strata.withColumn(\n",
    "    \"StrataGrouping\",\n",
    "    when(col(\"StrataGrouping\").isNull(), lit(\"Other\")).otherwise(col(\"StrataGrouping\"))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------+--------------------+\n",
      "|      StrataGrouping|  count|          proportion|\n",
      "+--------------------+-------+--------------------+\n",
      "|               Other|2377353|  0.3002525687548277|\n",
      "|Credit Card_76_Lo...| 932993| 0.11783422355883748|\n",
      "|Other_Other_Urban...| 447407| 0.05650616506210529|\n",
      "|Other_Other_Long-...| 430338| 0.05435040144766681|\n",
      "|Cash_Other_Flash ...| 310727| 0.03924389012968682|\n",
      "| Cash_8_Flash Riders| 306484| 0.03870801192849973|\n",
      "|Credit Card_32_Fl...| 291907|0.036866980455790746|\n",
      "|Credit Card_8_Fla...| 276498| 0.03492086987316244|\n",
      "|Cash_32_Flash Riders| 255828| 0.03231031073610442|\n",
      "|Mobile_8_Flash Ri...| 225234|0.028446380100441485|\n",
      "|Credit Card_Other...| 211508|0.026712827380786994|\n",
      "|Cash_76_Long-Haul...| 206361|0.026062776685168335|\n",
      "|Cash_Other_Long-H...| 205220| 0.02591867180005062|\n",
      "|Mobile_Other_Urba...| 203128|0.025654458461166953|\n",
      "|Credit Card_76_Ur...| 199533|  0.0252004207205901|\n",
      "|Cash_Other_Urban ...| 194488| 0.02456325231969713|\n",
      "|Credit Card_8_Urb...| 183293|0.023149357325049597|\n",
      "|Mobile_8_Urban Cr...| 179042| 0.02261246874780559|\n",
      "|Credit Card_Other...| 162120|0.020475270793412954|\n",
      "|Cash_8_Urban Crui...| 159390|0.020130479963990196|\n",
      "|Credit Card_28_Fl...| 158992|0.020080213755158602|\n",
      "+--------------------+-------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped_partition_counts = dftaxytrips_with_strata.groupBy(\n",
    "    \"StrataGrouping\"\n",
    ").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "# Agregar proporción por combinación\n",
    "grouped_partition_counts = grouped_partition_counts.withColumn(\n",
    "    \"proportion\", col(\"count\") / total_count\n",
    ")\n",
    "\n",
    "# Ordenar por las más representativas\n",
    "grouped_partition_counts.orderBy(col(\"proportion\").desc()).show(60)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6RaPEv3N3B-k"
   },
   "source": [
    "#### **Técnica de Muestreo**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora que se tiene la columna \"StrataGrouping\" podemos usar muestreo estratificado, para esto primero creamos un diccionario que tome los valores únicos de \"StrataGrouping\" y les asigne el porcentaje de valores que se tomaría de la población de dicho segmento, después se utiliza la función \"SampleBy\" para realizar la extracción de los datos.\n",
    "\n",
    "En nuestro caso se optó por utilizar el 15% de los datos de cada estrato, esto nos permite ahorrar una cantidad considerable de recursos de procesamiento y almacenamiento, mientras que mantiene la distribución de los datos sin afectar a ningún estrato, manteniendo la integridad de nuestra población en la muestra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fractions_df = dftaxytrips_with_strata.select(\"StrataGrouping\").distinct().withColumn(\"fraction\",lit(0.15))\n",
    "fractions_dict = fractions_df.rdd.collectAsMap()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = dftaxytrips_with_strata.stat.sampleBy(\"StrataGrouping\", fractions_dict, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_total_count = sampled_df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+------+--------------------+\n",
      "|      StrataGrouping| count|          proportion|\n",
      "+--------------------+------+--------------------+\n",
      "|               Other|356854| 0.30022976553146846|\n",
      "|Credit Card_76_Lo...|140422| 0.11814037151176633|\n",
      "|Other_Other_Urban...| 67046| 0.05640739590931539|\n",
      "|Other_Other_Long-...| 64443| 0.05421743004182221|\n",
      "|Cash_Other_Flash ...| 46794| 0.03936890618650635|\n",
      "| Cash_8_Flash Riders| 46027| 0.03872361082716433|\n",
      "|Credit Card_32_Fl...| 44029|0.037042645862411586|\n",
      "|Credit Card_8_Fla...| 41543| 0.03495111488024176|\n",
      "|Cash_32_Flash Riders| 38282| 0.03220755794828046|\n",
      "|Mobile_8_Flash Ri...| 33494|  0.0281792995642784|\n",
      "|Credit Card_Other...| 31932|0.026865151779021254|\n",
      "|Cash_Other_Long-H...| 30787| 0.02590183602094223|\n",
      "|Mobile_Other_Urba...| 30682|0.025813497021293066|\n",
      "|Cash_76_Long-Haul...| 30650|0.025786574659495222|\n",
      "|Credit Card_76_Ur...| 29751|0.025030224557737107|\n",
      "|Cash_Other_Urban ...| 29284|0.024637326340249857|\n",
      "|Credit Card_8_Urb...| 27575|0.023199503955483876|\n",
      "|Mobile_8_Urban Cr...| 26774| 0.02252560358673165|\n",
      "|Cash_8_Urban Crui...| 24145| 0.02031376330027772|\n",
      "|Credit Card_Other...| 24096|0.020272538433774776|\n",
      "|Credit Card_28_Fl...| 23993|0.020185882081737973|\n",
      "+--------------------+------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_partition_counts = sampled_df.groupBy(\n",
    "    \"StrataGrouping\"\n",
    ").agg(count(\"*\").alias(\"count\"))\n",
    "\n",
    "# Agregar proporción por combinación\n",
    "sampled_partition_counts = sampled_partition_counts.withColumn(\n",
    "    \"proportion\", col(\"count\") / sampled_total_count \n",
    ")\n",
    "\n",
    "# Ordenar por las más representativas\n",
    "sampled_partition_counts.orderBy(col(\"proportion\").desc()).show(60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1188603\n"
     ]
    }
   ],
   "source": [
    "print(sampled_total_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7917844\n"
     ]
    }
   ],
   "source": [
    "print(total_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preprocesamiento**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Eliminación de columnas no importantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- payment_group: string (nullable = false)\n",
      " |-- pickup_zone_group: string (nullable = false)\n",
      " |-- duration_group: string (nullable = false)\n",
      " |-- trip_id: string (nullable = true)\n",
      " |-- Taxi ID: string (nullable = true)\n",
      " |-- Trip Start Timestamp: string (nullable = true)\n",
      " |-- Trip End Timestamp: string (nullable = true)\n",
      " |-- Trip Seconds: integer (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- Pickup Census Tract: long (nullable = true)\n",
      " |-- Dropoff Census Tract: long (nullable = true)\n",
      " |-- Pickup Community Area: integer (nullable = true)\n",
      " |-- Dropoff Community Area: integer (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tips: double (nullable = true)\n",
      " |-- Tolls: double (nullable = true)\n",
      " |-- Extras: double (nullable = true)\n",
      " |-- Trip Total: double (nullable = true)\n",
      " |-- Payment Type: string (nullable = true)\n",
      " |-- Company: string (nullable = true)\n",
      " |-- Pickup Centroid Latitude: double (nullable = true)\n",
      " |-- Pickup Centroid Longitude: double (nullable = true)\n",
      " |-- Pickup Centroid Location: string (nullable = true)\n",
      " |-- Dropoff Centroid Latitude: double (nullable = true)\n",
      " |-- Dropoff Centroid Longitude: double (nullable = true)\n",
      " |-- Dropoff Centroid  Location: string (nullable = true)\n",
      " |-- trip_start_ts: timestamp (nullable = true)\n",
      " |-- trip_hour: integer (nullable = true)\n",
      " |-- trip_day_of_week: integer (nullable = true)\n",
      " |-- trip_month: integer (nullable = true)\n",
      " |-- duration_minutes: double (nullable = true)\n",
      " |-- tip_ratio: double (nullable = true)\n",
      " |-- tip_per_mile: double (nullable = true)\n",
      " |-- company_group: string (nullable = false)\n",
      " |-- dropoff_zone_group: string (nullable = false)\n",
      " |-- StrataGrouping: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Estructura del dataset\n",
    "sampled_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En nuestro dataset podemos observar que existen múltiples columnas dedicadas a representar datos de localización, esto complica nuestro modelo sin aportar información significativa, por lo que eliminaremos todas menos 'pickup_zone_group' y 'dropoff_zone_group', las cuales construimos con anterioridad por esta misma razón.\n",
    "\n",
    "Además, la columna 'Trip Minutes' se calculó directamente de la columna 'Trip Seconds', por lo que eliminamos esta última para evitar problemas de colinealidad. Las columnas 'trip_id' y 'taxi_id' no presentan valores importantes para nuestro análisis, por lo que se pueden eliminar. Y las columnas 'Trip Start Timestamp', 'Trip End Timestamp' y 'trip_start_ts' presentan un problema similar a las anteriores, donde sus valores están representados en otras columnas o no contribuyen con información importante para nuestro análisis, por lo que las podemos eliminar. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sampled_df.drop('Pickup Census Tract','Dropoff Census Tract','Pickup Community Area','Dropoff Community Area','Pickup Centroid Longitude','Pickup Centroid Latitude','Dropoff Centroid Latitude','Pickup Centroid Location','Dropoff Centroid Longitude','Dropoff Centroid  Location','Taxi ID','trip_id','Trip Seconds','Trip Start Timestamp', 'Trip End Timestamp','trip_start_ts','Payment Type','Company','StrataGrouping')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Manejo de datos faltantes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "missing_taxytrips = sampled_df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in sampled_df.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes en nuestra muestra:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_group</th>\n",
       "      <th>pickup_zone_group</th>\n",
       "      <th>duration_group</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Tips</th>\n",
       "      <th>Tolls</th>\n",
       "      <th>Extras</th>\n",
       "      <th>Trip Total</th>\n",
       "      <th>trip_hour</th>\n",
       "      <th>trip_day_of_week</th>\n",
       "      <th>trip_month</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>tip_ratio</th>\n",
       "      <th>tip_per_mile</th>\n",
       "      <th>company_group</th>\n",
       "      <th>dropoff_zone_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>3049</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244</td>\n",
       "      <td>0</td>\n",
       "      <td>2790</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Valores faltantes en nuestra muestra:\")\n",
    "pretty_display(missing_taxytrips)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que nuestro objetivo es predecir los valores de Tip, es importante eliminar aquellos casos en los cuales esta columna tenga valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_df = sampled_df.where(sampled_df.Tips != 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para las columnas numéricas restantes podemos definir un imputador simple que use el promedio de cada columna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables numéricas a imputar\n",
    "vars_a_imputar = [\"duration_minutes\", \"trip_miles\", \"Fare\",\"Tolls\",\"Extras\",\"Trip Total\",\"tip_ratio\", \"tip_per_mile\"]\n",
    "\n",
    "# Aplicamos imputación con mediana\n",
    "for var in vars_a_imputar:\n",
    "    mediana = sampled_df.approxQuantile(var, [0.5], 0.01)[0]\n",
    "    sampled_df = sampled_df.withColumn(\n",
    "        var, when(col(var).isNull(), mediana).otherwise(col(var))\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el caso de las variables categóricas definimos un imputador que use un valor comodín para asegurarnos que no existan valores nulos en el futuro.\n",
    "\n",
    "Mientras que las variables \"trip_hour\",\"trip_day_of_week\" y \"trip_month\" son de tipo numéricas, estas representan valores categóricos (hora, día de la semana y mes) por lo que las consideraré como variables categóricas y tendrán un imputador separado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista de variables numéricas a imputar\n",
    "vars_a_imputar = [\"payment_group\", \"pickup_zone_group\", \"duration_group\",\"company_group\",\"dropoff_zone_group\"]\n",
    "\n",
    "# Aplicamos imputación con mediana\n",
    "for var in vars_a_imputar:\n",
    "    sampled_df = sampled_df.withColumn(\n",
    "        var, when(col(var).isNull(), \"NA\").otherwise(col(var))\n",
    "    )\n",
    "vars_a_imputar = [\"trip_hour\",\"trip_day_of_week\",\"trip_month\"]\n",
    "\n",
    "# Aplicamos imputación con mediana\n",
    "for var in vars_a_imputar:\n",
    "    sampled_df = sampled_df.withColumn(\n",
    "        var, when(col(var).isNull(), 0).otherwise(col(var))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Análisis de valores faltantes en 'dftaxytrips_selected'\n",
    "missing_taxytrips = sampled_df.select([\n",
    "    count(when(col(c).isNull(), c)).alias(c)\n",
    "    for c in sampled_df.columns\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores faltantes en Chicago Taxi Trips Dataset (csv):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>payment_group</th>\n",
       "      <th>pickup_zone_group</th>\n",
       "      <th>duration_group</th>\n",
       "      <th>trip_miles</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Tips</th>\n",
       "      <th>Tolls</th>\n",
       "      <th>Extras</th>\n",
       "      <th>Trip Total</th>\n",
       "      <th>trip_hour</th>\n",
       "      <th>trip_day_of_week</th>\n",
       "      <th>trip_month</th>\n",
       "      <th>duration_minutes</th>\n",
       "      <th>tip_ratio</th>\n",
       "      <th>tip_per_mile</th>\n",
       "      <th>company_group</th>\n",
       "      <th>dropoff_zone_group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Valores faltantes en Chicago Taxi Trips Dataset (csv):\")\n",
    "pretty_display(missing_taxytrips)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- payment_group: string (nullable = false)\n",
      " |-- pickup_zone_group: string (nullable = false)\n",
      " |-- duration_group: string (nullable = false)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- Fare: double (nullable = true)\n",
      " |-- Tips: double (nullable = true)\n",
      " |-- Tolls: double (nullable = true)\n",
      " |-- Extras: double (nullable = true)\n",
      " |-- Trip Total: double (nullable = true)\n",
      " |-- trip_hour: integer (nullable = true)\n",
      " |-- trip_day_of_week: integer (nullable = true)\n",
      " |-- trip_month: integer (nullable = true)\n",
      " |-- duration_minutes: double (nullable = true)\n",
      " |-- tip_ratio: double (nullable = true)\n",
      " |-- tip_per_mile: double (nullable = true)\n",
      " |-- company_group: string (nullable = false)\n",
      " |-- dropoff_zone_group: string (nullable = false)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sampled_df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Manejo de valores atípicos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero definimos funciones auxiliares que nos ayudaran a detectar y eliminar valores atípicos. Es importante considerar que aunque no se detecten valores atípicos en la muestra actual, se incluyo una sección donde estos se eliminan para prevenirnos a su ocurrencia en otras muestras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_outliers(df, column):\n",
    "    percentiles = df.approxQuantile(column, [0.25, 0.75], 0.05) \n",
    "    Q1 = percentiles[0]\n",
    "    Q3 = percentiles[1]\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    return df.filter((col(column) < lower_limit) & (col(column) > upper_limit)).count()\n",
    "\n",
    "def remove_outliers_inplace(df, column):\n",
    "    \n",
    "    percentiles = df.approxQuantile(column, [0.25, 0.75], 0.05) \n",
    "    Q1 = percentiles[0]\n",
    "    Q3 = percentiles[1]\n",
    "\n",
    "    IQR = Q3 - Q1\n",
    "\n",
    "    lower_limit = Q1 - 1.5 * IQR\n",
    "    upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "    df = df.filter((col(column) >= lower_limit) & (col(column) <= upper_limit))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valores atípicos para duration_minutes: 0\n",
      "Valores atípicos para trip_miles: 0\n",
      "Valores atípicos para Fare: 0\n",
      "Valores atípicos para Tips: 0\n",
      "Valores atípicos para Tolls: 0\n",
      "Valores atípicos para Extras: 0\n",
      "Valores atípicos para Trip Total: 0\n",
      "Valores atípicos para tip_ratio: 0\n",
      "Valores atípicos para tip_per_mile: 0\n"
     ]
    }
   ],
   "source": [
    "NumVar = [\"duration_minutes\", \"trip_miles\", \"Fare\",\"Tips\",\"Tolls\",\"Extras\",\"Trip Total\",\"tip_ratio\", \"tip_per_mile\"]\n",
    "for i in NumVar:\n",
    "    outlier_count = count_outliers(sampled_df, i)\n",
    "    print(f\"Valores atípicos para {i}: {outlier_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos código que maneje los valores atípicos en caso de que ocurran  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_no_outlier_df = sampled_df\n",
    "for i in NumVar:\n",
    "    sampled_no_outlier_df = remove_outliers_inplace(sampled_df, i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Preparación del conjunto de entrenamiento y prueba**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evitar problemas de inyección de sesgos se hace la separación del conjunto de entrenamiento y prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = sampled_no_outlier_df.randomSplit([0.7, 0.3], seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Transformación de datos categóricos**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos de PySpark no permiten el uso de columnas que no sean de tipo numérico, por lo que las siguientes columnas tendrán que ser transformadas utilizando un \"StringIndexer\", además, se utilizara la técnica de one hot encoding para evitar que se infieran relaciones numéricas donde no las hay. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexer = StringIndexer(\n",
    "            inputCols=[\"payment_group\",\"company_group\",\"pickup_zone_group\",\"dropoff_zone_group\",\"duration_group\"], \n",
    "            outputCols= [\"payment_group_cat\",\"company_group_cat\",\"pickup_zone_group_cat\",\"dropoff_zone_group_cat\",\"duration_group_cat\"])\n",
    "indexerFit = indexer.fit(train_df)\n",
    "train_indexed_df = indexerFit.transform(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indexed_df = train_indexed_df.select(\n",
    " 'trip_miles',\n",
    " 'Fare',\n",
    " 'Tips',\n",
    " 'Tolls',\n",
    " 'Extras',\n",
    " 'Trip Total',\n",
    " 'trip_hour',\n",
    " 'trip_day_of_week',\n",
    " 'trip_month',\n",
    " 'duration_minutes',\n",
    " 'tip_ratio',\n",
    " 'tip_per_mile',\n",
    " 'payment_group_cat',\n",
    " 'company_group_cat',\n",
    " 'pickup_zone_group_cat',\n",
    " 'dropoff_zone_group_cat',\n",
    " 'duration_group_cat')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(\n",
    "            inputCols=[\"payment_group_cat\",\"company_group_cat\",\"pickup_zone_group_cat\",\"dropoff_zone_group_cat\",\"duration_group_cat\",\"trip_hour\", \"trip_day_of_week\", \"trip_month\"], \n",
    "            outputCols= [\"payment_group_ohe\",\"company_group_ohe\",\"pickup_zone_group_ohe\",\"dropoff_zone_group_ohe\",\"duration_group_ohe\",\"trip_hour_ohe\", \"trip_day_of_week_ohe\", \"trip_month_ohe\"])\n",
    "encoderFit = encoder.fit(train_indexed_df)\n",
    "train_encoded_df = encoderFit.transform(train_indexed_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encoded_df = train_encoded_df.select(\n",
    " 'trip_miles',\n",
    " 'Fare',\n",
    " 'Tips',\n",
    " 'Tolls',\n",
    " 'Extras',\n",
    " 'Trip Total',\n",
    " 'trip_hour_ohe',\n",
    " 'trip_day_of_week_ohe',\n",
    " 'trip_month_ohe',\n",
    " 'duration_minutes',\n",
    " 'tip_ratio',\n",
    " 'tip_per_mile',\n",
    " 'payment_group_ohe',\n",
    " 'company_group_ohe',\n",
    " 'pickup_zone_group_ohe',\n",
    " 'dropoff_zone_group_ohe',\n",
    " 'duration_group_ohe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Transformación de datos numéricos para modelo de aprendizaje supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Debido a que los datos numéricos se presentan en distintas escalas y a que no existen valores atípicos (nos encargamos de estos en pasos anteriores), se optó por utilizar un standard scaler para transformar estas columnas. \n",
    "\n",
    "Es importante señalar que no se modifica la columna de Tip, ya que es nuestra columna objetivo para el algoritmo de aprendizaje supervisado. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = [\"duration_minutes\", \"trip_miles\", \"Fare\", \"Tolls\", \"Extras\", \"Trip Total\", \"tip_ratio\", \"tip_per_mile\"]\n",
    "assembler = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features_vec\")\n",
    "train_encoded_num_vectorized_df = assembler.transform(train_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler(\n",
    "    inputCol=\"numeric_features_vec\",\n",
    "    outputCol=\"numeric_features_scaled\",\n",
    "    withMean=True, \n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "scalerFit = scaler.fit(train_encoded_num_vectorized_df)  \n",
    "train_encoded_num_scaled_df = scalerFit.transform(train_encoded_num_vectorized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **DataFrame final para modelo de aprendizaje supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se genera el DataFrame final para el modelo de aprendizaje supervisado. Para esto se utiliza un \"VectorAssembler\" que genere la columna \"features\" la cual contendrá vectores con todas las columnas anteriormente transformadas.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_features = [\"numeric_features_scaled\", 'payment_group_ohe',\n",
    " 'company_group_ohe',\n",
    " 'pickup_zone_group_ohe',\n",
    " 'dropoff_zone_group_ohe',\n",
    " 'duration_group_ohe','trip_hour_ohe',\n",
    " 'trip_day_of_week_ohe']  \n",
    "assembler_final = VectorAssembler(inputCols=final_features, outputCol=\"features\")\n",
    "train_final_df = assembler_final.transform(train_encoded_num_scaled_df )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_df = train_final_df.select('features','tips')\n",
    "train_final_df = train_final_df.withColumnRenamed(\"tips\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Transformando el set de testing para modelo de aprendizaje supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Además, transformamos nuestro dataset de prueba, cuidando de no utilizar la función fit en ninguno de nuestros transformadores. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_indexed_df = indexerFit.transform(test_df)\n",
    "test_encoded_df = encoderFit.transform(test_indexed_df)\n",
    "test_vectorized_df = assembler.transform(test_encoded_df)\n",
    "test_scaled_df = scalerFit.transform(test_vectorized_df)\n",
    "test_final_df = assembler_final.transform(test_scaled_df)\n",
    "test_final_df = test_final_df.select('features','tips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_final_df  = test_final_df .withColumnRenamed(\"tips\", \"label\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Transformación de datos numéricos para modelo de aprendizaje no supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A continuación se repiten los pasos anteriores para el dataset del modelo de aprendizaje no supervisado, la diferencia principal siendo que este incluye la columna \"tips\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols_nonSup = [\"duration_minutes\", \"trip_miles\", \"Fare\", \"Tolls\", \"Extras\", \"Trip Total\", \"tip_ratio\", \"tip_per_mile\",\"tips\"]\n",
    "assembler_nonSup = VectorAssembler(inputCols=numeric_cols, outputCol=\"numeric_features_vec\")\n",
    "train_vectorized_df_nonSup = assembler.transform(train_encoded_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler_nonSup = StandardScaler(\n",
    "    inputCol=\"numeric_features_vec\",\n",
    "    outputCol=\"numeric_features_scaled\",\n",
    "    withMean=True, \n",
    "    withStd=True\n",
    ")\n",
    "\n",
    "scalerFit_nonSup = scaler.fit(train_vectorized_df_nonSup)  \n",
    "train_scaled_df_nonSup = scalerFit.transform(train_vectorized_df_nonSup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **DataFrame final para modelo de aprendizaje no supervisado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_df_nonSup = assembler_final.transform(train_scaled_df_nonSup )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_final_df_nonSup = train_final_df.select('features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### **Transformando el set de testing para modelo de aprendizaje no supervisado**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_vectorized_nonSup_df = assembler_nonSup.transform(test_encoded_df)\n",
    "test_scaled_nonSup_df = scalerFit_nonSup.transform(test_vectorized_df)\n",
    "test_final_nonSup_df = assembler_final.transform(test_scaled_df)\n",
    "test_final_nonSup_df = test_final_nonSup_df .select('features')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creación de modelo de aprendizaje supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para nuestro problema que utilice aprendizaje supervisado, utilizaremos regresión lineal para predecir los valores de la columna 'tips'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestro modelo y los parámetros a usar en nuestro grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "paramGrid = ParamGridBuilder().addGrid(lr.regParam, [0.0, 0.01, 0.1]).addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0]).build()\n",
    "evaluator = RegressionEvaluator(metricName=\"rmse\") \n",
    "cv = CrossValidator(\n",
    "    estimator=lr,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=3, \n",
    "    parallelism=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entrenamos nuestro grid search y obtenemos el mejor modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model = cv.fit(train_final_df)\n",
    "best_model = cv_model.bestModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imprimimos los parametros de nuestro modelo y verificamos el rendimiento en nuestro set de datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parametros de mejor modelo:\n",
      "  regParam: 0.0\n",
      "  elasticNetParam: 0.0\n",
      "RMSE en set de prueba: 0.3389000723663502\n"
     ]
    }
   ],
   "source": [
    "predictions = best_model.transform(test_final_df)\n",
    "rmse = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"Parametros de mejor modelo:\")\n",
    "print(f\"  regParam: {best_model._java_obj.getRegParam()}\")\n",
    "print(f\"  elasticNetParam: {best_model._java_obj.getElasticNetParam()}\")\n",
    "print(f\"RMSE en set de prueba: {rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------------------+\n",
      "|label|        prediction|\n",
      "+-----+------------------+\n",
      "|  2.0|2.1460191983007038|\n",
      "|  3.0| 3.113884371945795|\n",
      "|  1.0|1.1283108188735556|\n",
      "|  2.0| 2.128203154836537|\n",
      "|  9.5| 9.448396205437547|\n",
      "+-----+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predictions.select(\"label\", \"prediction\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mostramos métricas de nuestra columna objetivo para contextualizar nuestros resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+-----------------+----------+----------+\n",
      "|       mean(label)|    stddev(label)|min(label)|max(label)|\n",
      "+------------------+-----------------+----------+----------+\n",
      "|6.0354008949752345|4.440883954488067|      0.01|     150.0|\n",
      "+------------------+-----------------+----------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_final_df.selectExpr(\"mean(label)\", \"stddev(label)\", \"min(label)\", \"max(label)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Creación de modelo de aprendizaje no supervisado**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el caso del modelo de aprendizaje no supervisado, se optó por utilizar KMeans para realizar agrupamientos en nuestra población. Esto podría de ser de gran utilidad comercial para comprender mejor los patrones de comportamiento de los consumidores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos los valores a utilizar nuestro GridSearch y el evaluador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_values = [2, 4, 6, 8]\n",
    "max_iter_values = [10, 20]\n",
    "evaluator = ClusteringEvaluator()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizamos el GridSearch, como PySpark no cuenta con una implementación nativa, utilizaremos dos fors anidados. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = None\n",
    "best_score = float('-inf')\n",
    "best_params = {}\n",
    "\n",
    "for k in k_values:\n",
    "    for max_iter in max_iter_values:\n",
    "        kmeans = KMeans(k=k, maxIter=max_iter, seed=1)\n",
    "        model = kmeans.fit(train_final_df_nonSup)\n",
    "        predictions = model.transform(train_final_df_nonSup)\n",
    "        \n",
    "        score = evaluator.evaluate(predictions) \n",
    "        \n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_model = model\n",
    "            best_params = {\"k\": k, \"maxIter\": max_iter}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mejores Parametros={'k': 2, 'maxIter': 10}, Mejor Resultado=0.4181930478893609\n"
     ]
    }
   ],
   "source": [
    "print(f\"Mejores Parametros={best_params}, Mejor Resultado={best_score}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tomamos el mejor modelo y lo probamos con nuestros datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Resultado del modelo con datos de prueba = 0.4313\n"
     ]
    }
   ],
   "source": [
    "testResults = evaluator.evaluate(best_model.transform(test_final_nonSup_df))\n",
    "print(f\"Resultado del modelo con datos de prueba = {testResults:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
